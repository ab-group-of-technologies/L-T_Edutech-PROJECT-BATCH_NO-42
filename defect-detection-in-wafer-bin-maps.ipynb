{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":19086,"sourceType":"datasetVersion","datasetId":14180}],"dockerImageVersionId":30154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Our goal here is to identify different types of wafer map failure pattern automatically, so that its construction can\n#be improved, by increasing the accuracy of the manufacturing process.\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport os\nfrom os.path import join\n\nimport numpy as np\nimport pandas as pd\nimport scipy.io as sio\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers, Input, models\n#from keras.utils import to_categorical\nfrom keras.wrappers.scikit_learn import KerasClassifier \nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nwafer_bins=pd.read_pickle(\"../input/wm811k-wafer-map/LSWMD.pkl\")\nwafer_bins.info()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can see that we will be able to use 811457 wafermaps for the deep learning to detect all detections\n\n#After having looked in the dataset, we can see that there is several types of mapping (9 precisely), and data\n#either for the training or the test. So let's rearrange these information.\n\nwafer_bins['failureNum']=wafer_bins.failureType\nwafer_bins['trainTestNum']=wafer_bins.trianTestLabel\nmapping_type={'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8}\nmapping_traintest={'Training':0,'Test':1}\nwafer_bins=wafer_bins.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest})\n\ndef find_dim(x):\n    dim0=np.size(x,axis=0)\n    dim1=np.size(x,axis=1)\n    return dim0,dim1\nwafer_bins['waferMapDim']=wafer_bins.waferMap.apply(find_dim)\n\nwafer_bins.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In this document, we have to choose which wafermaps we need. Because, there are many in which we can see that the \n#labels have a pattern (we need these ones), and some label without a pattern.\n\n#From now on, I will call the variable wafer_bins wb.\nwb=wafer_bins\n\n#Our database will be reduced for sure, so let's see how much it will be.\n\nwb_withlabel = wb[(wb['failureNum']>=0) & (wb['failureNum']<=8)]\nwb_withlabel =wb_withlabel.reset_index()\nwb_withpattern = wb[(wb['failureNum']>=0) & (wb['failureNum']<=7)]\nwb_withpattern = wb_withpattern.reset_index()\nwb_nonpattern = wb[(wb['failureNum']==8)]\nprint(wb_withlabel.shape[0], wb_withpattern.shape[0], wb_nonpattern.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As we can see, we only choose those we need, so we just don't study the None failure types nor the non-labelled\n#wafer maps. So we just keep the 25519 wafer maps we need, it really reduces the amount of work. But we still have to\n#remove the null label. And from now on, we will work with this reduced database.\n\nwb=wb_withpattern\nfor i in range(len(wb)):\n    if len(wb.iloc[i,:]['failureType']) == 0:\n        wb.remove(wb[i])\n\n#Let's show how is organized the distribution of the Failure Types:\n\n%matplotlib inline\n\nfig = plt.figure(figsize=(15, 5))\naxe=plt.subplot(1,1,1)\n\nuni_pattern=np.unique(wb.failureNum, return_counts=True)\nlabels = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full']\naxe.bar(uni_pattern[0],uni_pattern[1], color='blue', align='center', alpha=0.9)\naxe.set_title(\"number  of failure types in wafer maps\")\naxe.set_ylabel(\"number of pattern wafers\")\naxe.set_xticklabels(labels)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we have all the Failure Types we want, we will be able to start the deep learning, and as this problem is\n#sequential, we will use the sequence to sequence model.\n\n#So now, let's settle the parameters of the encoder part.\n\n#Our encoder will be composed with a stack of several convolutional neutral networks (CNNs) units where each accepts a \n#single element of the input sequence, collects information for that element and propagates it forward.\n\n#But first, we need a precise shape for the wafer maps we will use, it has to be a square, so we have to choose a\n#shape, and then we have to create a list of images which are in this shape, and their associated failure types\n\nsub_wb = wb.loc[wb['waferMapDim'] == (26, 26)]\n\nImlist = np.ones((1, 26, 26))\nlabel = []\n\nfor i in range(len(sub_wb)):\n    Imlist = np.concatenate((Imlist, sub_wb.iloc[i,:]['waferMap'].reshape(1, 26, 26)))\n    label.append(sub_wb.iloc[i,:]['failureType'][0][0])\n    \n#The first elemet in Imlist is just composed with ones, so it isn't intersesting, let's remove it\nImlist=Imlist[1:]\nlabel=np.array(label).reshape((-1,1)) #Column of labels\nprint(Imlist[756][0][10], Imlist[756][0][9], Imlist[756][0][11])\n#We have all the values of the pixels: 0.0 is for the exterior ofthe wafer map, 2.0 is for the local impure pixel, and \n#1.0 is for a pure pixel of the wafer map\n\nprint(np.shape(Imlist),np.shape(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This not the most important part, but we can plot the defected wafer map, if we want to. The 511th data for example\nplt.imshow(Imlist[756])\nplt.show()\nprint(\"label assiociated : \", label[756])\n#Also we can see how much defect labels in this dataset\n\nfor l in np.unique(label) :\n    print('{} : {}'.format(l, len(label[label==l])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Imlist=Imlist.reshape((-1,26,26,1))\n#With that, each pixel of each image is separated and we will be able to use them separately in order to process the \n#deep learning\n\nnew_Imlist = np.zeros((len(Imlist), 26, 26, 3))\n\nfor w in range(len(Imlist)):\n    for i in range(26):\n        for j in range(26):\n            new_Imlist[w, i, j, int(Imlist[w, i, j])] = 1\n\n#In order to process to the deep learning, we have to use data compsed by 1 only. So we have to transform these\n#0.0, 1.0 or 2.0 in a sequence of 1 and 0. So with these loops, we can say:\n    #for 0.0: [1,0,0]\n    #for 1.0: [0,1,0]\n    #for 2.0: [0,0,1]\n#And now we can settle our process of deep learning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We have to prepare some data for the training and the test, and define the encoder and decoder.\n\nepoch=30\nbatch_size=877\n\ninput_shape = (26, 26, 3)\ninput_tensor = Input(input_shape)\nencode = layers.Conv2D(64, (3,3), padding='same', activation='relu')(input_tensor)\n#Relu activation function, in this case, just keep the values we are convoluting, and it let us do the same for the\n#output tensor created.\n\n#Now that the encoder is settled, we have to code the latent vector, which is the last part of the encoder, and it aims \n#to encapsulate the information for all input elements in order to help the decoder make accurate predictions.\n#It acts as the initial hidden state of the decoder part of the model.\n\n#Only the highest value of a region is kept.Max pooling is akeeping the most activated pixels (ones with the highest \n#values) and discards the rest.\n\nlatent_vector = layers.MaxPool2D()(encode)\n\nencoder = models.Model(input_tensor, latent_vector)\n\n#And now the decoder, and then connecting all the layers, to finally have the predicted output tensor. A stack of \n#several recurrent units where each predicts an outputEach recurrent unit accepts a hidden state from the previous \n#unit and produces and output as well as its own hidden state.\n\ndecode_layer_1 = layers.Conv2DTranspose(64, (3,3), padding='same', activation='relu') #It is the transposed \n#convolution layer, so the inverse step as the encoder\ndecode_layer_2 = layers.UpSampling2D() #Repeats the rows and columns of the data by size[0] and size[1] respectively.\noutput_tensor = layers.Conv2DTranspose(3, (3,3), padding='same', activation='sigmoid')\n\n#After having regarding the shape I needed for the start of the decoder, I have to define it.\ndecoder_input = Input((13, 13, 64))\ndecode = decode_layer_1(decoder_input)\ndecode = decode_layer_2(decode)\n\ndecoder = models.Model(decoder_input, output_tensor(decode))\n\n#Now we have all the model, let's prepare the dataset, with normal wafers, and noised wafers, so that we will have some \n#data to make the machine predict their label\n\nencoded_Im = encoder.predict(new_Imlist)\nnoised_encoded_Im = encoded_Im + np.random.normal(loc=0, scale=0.1, size = (len(encoded_Im), 13, 13, 64))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#When you train a deep learning model, what you’re really doing is tuning its parameters such that it can map a \n#particular input (say, an image) to some output (a label). Our optimization goal is to chase that sweet spot where our \n#model’s loss is low, which happens when your parameters are tuned in the right way.\n\n#So, to get more data, we just need to make minor alterations to our existing dataset. Minor changes such as flips or \n#translations or rotations. Our neural network would think these are distinct images anyway.\n\n#So here is our augmentation function\n\ndef gen_data(wafer, label):\n    encoded_x = encoder.predict(wafer)\n    \n    gen_x = np.zeros((1, 26, 26, 3)) # Dummy array for collecting noised wafer\n    \n    for i in range((1500//len(wafer)) + 1): # Make wafer until total of wafer to 1500\n        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64)) \n        noised_gen_x = decoder.predict(noised_encoded_x)\n        gen_x = np.concatenate((gen_x, noised_gen_x), axis=0)\n    \n    gen_y = np.full((len(gen_x), 1), label) # Also make label vector with same length\n    \n    return gen_x[1:], gen_y[1:]  # Return date without 1st dummy data.\n\n#And we can apply this function to our dataset to have it full of noised wafer maps\n\nfor l in np.unique(label):\n    gen_x, gen_y = gen_data(new_Imlist[np.where(label==l)[0]], l)\n    new_Imlist = np.concatenate((new_Imlist, gen_x), axis=0)\n    label = np.concatenate((label, gen_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we can see the shape of our lists, just to now how big is our dataset\nfor l in np.unique(label) :\n    print('{} : {}'.format(l, len(label[label==l])))\nprint(np.shape(new_Imlist), np.shape(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In order to process the test, we need a matrix of labels\nfor i, l in enumerate(np.unique(label)):\n    label[label==l] = i\n    \nlabel = tf.keras.utils.to_categorical(label)\n\n#Now we know this information, we can lower the heavyness of the dataset, because it is too huge\nnew_IMLIST=new_Imlist[0:13000]\nnew_LABEL=label[0:13000]\ntest_Imlist=new_Imlist[13001:13554]\ntest_label=label[13001:13554]\nprint(np.shape(new_LABEL))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We have to split our slighter dataset in order to process the test\nim_train, im_test, label_train, label_test = train_test_split(new_IMLIST, new_LABEL, test_size=0.33, random_state=2019)\nprint(np.shape(im_train),np.shape(im_test),np.shape(label_train),np.shape(label_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's now create the real model we will use for the CNN test\ndef create_model():\n    input_shape = (26, 26, 3)\n    input_tensor = Input(input_shape)\n\n    conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n    conv_2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv_1)\n    conv_3 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv_2)\n\n    flat = layers.Flatten()(conv_3)\n\n    dense_1 = layers.Dense(512, activation='relu')(flat)\n    dense_2 = layers.Dense(128, activation='relu')(dense_1)\n    output_tensor = layers.Dense(8, activation='softmax')(dense_2)\n\n    model = models.Model(input_tensor, output_tensor)\n    model.compile(optimizer='Adam',\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =KerasClassifier(build_fn=create_model, epochs=30, batch_size=877, verbose=2) \n# 3-Fold Crossvalidation\nkfold = KFold(n_splits=3, shuffle=True, random_state=2019) \nresults = cross_val_score(model, im_train, label_train, cv=kfold)\nprint(results)\nprint(\"training accuracy = \", np.mean(results))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we have done the training is done, let's validate the learning with the test dataset\nhistory = model.fit(im_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(im_test, label_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#And finally let's see what is the testing accuracy\n\nscore = model.score(im_test, label_test)\nprint('Testing Accuracy:',score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's now plot the differnces in the losses and the accuracies between the training and the test\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}